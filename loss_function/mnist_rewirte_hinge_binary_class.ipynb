{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mnist_binary(images, labels, binary):\n",
    "#     binary = [binary[0]-1 , binary[1]-1]\n",
    "    select = [i for i,l in enumerate(labels) if sum(l[binary])>=1]\n",
    "    x = images[select]\n",
    "    y = labels[select][:,binary].astype(int)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "two_numbers = [5, 8]\n",
    "train_x, train_y = mnist_binary(mnist.train.images, mnist.train.labels, two_numbers)\n",
    "test_x, test_y = mnist_binary(mnist.test.images, mnist.test.labels, two_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var, name):\n",
    "  \"\"\"Attach a lot of summaries to a Tensor.\"\"\"\n",
    "  with tf.name_scope('summaries'):\n",
    "    mean = tf.reduce_mean(var)\n",
    "    tf.scalar_summary('mean/' + name, mean)\n",
    "    with tf.name_scope('stddev'):\n",
    "      stddev = tf.sqrt(tf.reduce_sum(tf.square(var - mean)))\n",
    "    tf.scalar_summary('sttdev/' + name, stddev)\n",
    "    tf.scalar_summary('max/' + name, tf.reduce_max(var))\n",
    "    tf.scalar_summary('min/' + name, tf.reduce_min(var))\n",
    "    tf.histogram_summary(name, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n",
    "    \"\"\"Reusable code for making a simple neural net layer.\n",
    "    It does a matrix multiply, bias add, and then uses relu to nonlinearize.\n",
    "    It also sets up name scoping so that the resultant graph is easy to read,\n",
    "    and adds a number of summary ops.\n",
    "    \"\"\"\n",
    "    # Adding a name scope ensures logical grouping of the layers in the graph.\n",
    "    with tf.name_scope(layer_name):\n",
    "      # This Variable will hold the state of the weights for the layer\n",
    "      with tf.name_scope('weights'):\n",
    "        weights = weight_variable([input_dim, output_dim])\n",
    "        variable_summaries(weights, layer_name + '/weights')\n",
    "      with tf.name_scope('biases'):\n",
    "        biases = bias_variable([output_dim])\n",
    "        variable_summaries(biases, layer_name + '/biases')\n",
    "      with tf.name_scope('Wx_plus_b'):\n",
    "        preactivate = tf.matmul(input_tensor, weights) + biases\n",
    "        tf.histogram_summary(layer_name + '/pre_activations', preactivate)\n",
    "      activations = act(preactivate, 'activation')\n",
    "      tf.histogram_summary(layer_name + '/activations', activations)\n",
    "      return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set variables\n",
    "with tf.name_scope('input'):\n",
    "  x = tf.placeholder(tf.float32, [None, 784], name='x-input') # 28*28\n",
    "  y_ = tf.placeholder(tf.float32, [None, 2], name='y-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('input_reshape'):\n",
    "  image_shaped_input = tf.reshape(x, [-1, 28, 28, 1])\n",
    "  tf.image_summary('input', image_shaped_input, 10) # 10 sample in IMAGES of tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set graphs and GRAPHS of tensorboard\n",
    "y = nn_layer(x, 784, 2, 'layer1', tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Set loss function\n",
    "# with tf.name_scope('cross_entropy'):\n",
    "#   diff = y_ * tf.log(y)\n",
    "#   with tf.name_scope('total'):\n",
    "#     cross_entropy = -tf.reduce_mean(diff)\n",
    "#   tf.scalar_summary('cross entropy', cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set hinge loss function\n",
    "with tf.name_scope('hinge_loss'):\n",
    "  with tf.name_scope('total'):\n",
    "    hinge_loss = tf.reduce_mean(tf.maximum(0., 1. - (y_[:,1] - y_[:,0])*y[:,1]))\n",
    "  tf.scalar_summary('hinge_loss', hinge_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set optimizer method\n",
    "with tf.variable_scope(\"trainer\") as scope:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "#     trainer = optimizer.minimize(cross_entropy)\n",
    "    trainer = optimizer.minimize(hinge_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('accuracy'):\n",
    "  with tf.name_scope('correct_prediction'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "  with tf.name_scope('accuracy'):\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "  tf.scalar_summary('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = tf.merge_all_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_writer = tf.train.SummaryWriter('mnist_logs' + '/train', sess.graph)\n",
    "test_writer = tf.train.SummaryWriter('mnist_logs' + '/test', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.578778 at times    0\n",
      "accuracy is 0.728296 at times   50\n",
      "accuracy is 0.824759 at times  100\n",
      "accuracy is 0.869775 at times  150\n",
      "accuracy is 0.885316 at times  200\n",
      "accuracy is 0.894427 at times  250\n",
      "accuracy is 0.901929 at times  300\n",
      "accuracy is 0.906217 at times  350\n",
      "accuracy is 0.906752 at times  400\n",
      "accuracy is 0.906217 at times  450\n",
      "accuracy is 0.909968 at times  500\n",
      "accuracy is 0.913719 at times  550\n",
      "accuracy is 0.914255 at times  600\n",
      "accuracy is 0.917471 at times  650\n",
      "accuracy is 0.92015 at times  700\n",
      "accuracy is 0.922294 at times  750\n",
      "accuracy is 0.92283 at times  800\n",
      "accuracy is 0.924437 at times  850\n",
      "accuracy is 0.927117 at times  900\n",
      "accuracy is 0.927653 at times  950\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000): # train 1000 times\n",
    "    sess.run(trainer, feed_dict={x: train_x, y_: train_y})\n",
    "    result = sess.run(merged, feed_dict={x: train_x, y_: train_y})\n",
    "    train_writer.add_summary(result, i)\n",
    "    if i % 50 == 0: # save summary if after train 50 times\n",
    "        result, acc = sess.run([merged, accuracy], feed_dict={x: test_x, y_: test_y})\n",
    "        test_writer.add_summary(result, i)\n",
    "        print \"accuracy is %0.8s at times %4d\" % (acc,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(y, feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(y_, feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(y[:,1], feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(y_[:,1]-y_[:,0], feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "margin = y_[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "margin[tf.cast(y_[:,0], dtype=bool)].assign(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess.run(1. - y_[:,1]*y[:,1], feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.maximum(0. ,1. + y_[:,1]*y[:,1]), feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_writer.close()\n",
    "test_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shell: \n",
    "```\n",
    "tensorboard --logdir=mnist_logs/\n",
    "```\n",
    "# Browser: http://127.0.0.1:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
