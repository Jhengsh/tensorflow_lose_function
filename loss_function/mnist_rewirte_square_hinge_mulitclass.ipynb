{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mnist_binary(images, labels, binary):\n",
    "#     binary = [binary[0]-1 , binary[1]-1]\n",
    "    select = [i for i,l in enumerate(labels) if sum(l[binary])>=1]\n",
    "    x = images[select]\n",
    "    y = labels[select][:,binary].astype(int)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3, 4, 5]\n",
    "train_x, train_y = mnist_binary(mnist.train.images, mnist.train.labels, numbers)\n",
    "test_x, test_y = mnist_binary(mnist.test.images, mnist.test.labels, numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len_numbers = len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var, name):\n",
    "  \"\"\"Attach a lot of summaries to a Tensor.\"\"\"\n",
    "  with tf.name_scope('summaries'):\n",
    "    mean = tf.reduce_mean(var)\n",
    "    tf.scalar_summary('mean/' + name, mean)\n",
    "    with tf.name_scope('stddev'):\n",
    "      stddev = tf.sqrt(tf.reduce_sum(tf.square(var - mean)))\n",
    "    tf.scalar_summary('sttdev/' + name, stddev)\n",
    "    tf.scalar_summary('max/' + name, tf.reduce_max(var))\n",
    "    tf.scalar_summary('min/' + name, tf.reduce_min(var))\n",
    "    tf.histogram_summary(name, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n",
    "    \"\"\"Reusable code for making a simple neural net layer.\n",
    "    It does a matrix multiply, bias add, and then uses relu to nonlinearize.\n",
    "    It also sets up name scoping so that the resultant graph is easy to read,\n",
    "    and adds a number of summary ops.\n",
    "    \"\"\"\n",
    "    # Adding a name scope ensures logical grouping of the layers in the graph.\n",
    "    with tf.name_scope(layer_name):\n",
    "      # This Variable will hold the state of the weights for the layer\n",
    "      with tf.name_scope('weights'):\n",
    "        weights = weight_variable([input_dim, output_dim])\n",
    "        variable_summaries(weights, layer_name + '/weights')\n",
    "      with tf.name_scope('biases'):\n",
    "        biases = bias_variable([output_dim])\n",
    "        variable_summaries(biases, layer_name + '/biases')\n",
    "      with tf.name_scope('Wx_plus_b'):\n",
    "        preactivate = tf.matmul(input_tensor, weights) + biases\n",
    "        tf.histogram_summary(layer_name + '/pre_activations', preactivate)\n",
    "      activations = act(preactivate, 'activation')\n",
    "      tf.histogram_summary(layer_name + '/activations', activations)\n",
    "      return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set variables\n",
    "with tf.name_scope('input'):\n",
    "  x = tf.placeholder(tf.float32, [None, 784], name='x-input') # 28*28\n",
    "  y_ = tf.placeholder(tf.float32, [None, len_numbers], name='y-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('input_reshape'):\n",
    "  image_shaped_input = tf.reshape(x, [-1, 28, 28, 1])\n",
    "  tf.image_summary('input', image_shaped_input, 10) # 10 sample in IMAGES of tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set graphs and GRAPHS of tensorboard\n",
    "y = nn_layer(x, 784, len_numbers, 'layer1', tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set loss function\n",
    "with tf.name_scope('cross_entropy'):\n",
    "  diff = y_ * tf.log(y + 1e-10)\n",
    "  with tf.name_scope('total'):\n",
    "    cross_entropy = -tf.reduce_mean(diff)\n",
    "  tf.scalar_summary('cross entropy', cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Set hinge loss function for binary class\n",
    "# with tf.name_scope('cross_entropy'):\n",
    "#   with tf.name_scope('total'):\n",
    "#     hinge_loss = tf.reduce_mean(tf.maximum(0., 1. - (y_[:,1] - y_[:,0])*y[:,1]))\n",
    "#   tf.scalar_summary('hinge_loss', hinge_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set hinge loss function for multiclass\n",
    "with tf.name_scope('cross_entropy'):\n",
    "  true_index = tf.cast(y_, dtype = bool)\n",
    "  margin = tf.boolean_mask(y, true_index)\n",
    "  false_prediction = tf.reshape(tf.boolean_mask(y, ~true_index), [tf.shape(y_)[0], len_numbers-1])\n",
    "  false_prediction_max = tf.reduce_max(false_prediction, reduction_indices=[1])\n",
    "  loss = 1 - (margin - false_prediction_max)\n",
    "  loss = tf.maximum(loss, tf.zeros_like(loss))\n",
    "  with tf.name_scope('total'):\n",
    "#     hinge_loss = tf.reduce_mean(loss)\n",
    "    hinge_loss = tf.reduce_mean(tf.square(loss))\n",
    "  tf.scalar_summary('hinge_loss', hinge_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsuehhungcheng/.pyenv/versions/anaconda-4.0.0/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py:90: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "# Set optimizer method\n",
    "with tf.variable_scope(\"trainer\") as scope:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "#     trainer = optimizer.minimize(cross_entropy)\n",
    "    trainer = optimizer.minimize(hinge_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('accuracy'):\n",
    "  with tf.name_scope('correct_prediction'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "  with tf.name_scope('accuracy'):\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "  tf.scalar_summary('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = tf.merge_all_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_writer = tf.train.SummaryWriter('mnist_logs' + '/train', sess.graph)\n",
    "test_writer = tf.train.SummaryWriter('mnist_logs' + '/test', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.158186 at times    0\n",
      "accuracy is 0.543853 at times   50\n",
      "accuracy is 0.677292 at times  100\n",
      "accuracy is 0.729163 at times  150\n",
      "accuracy is 0.765393 at times  200\n",
      "accuracy is 0.809741 at times  250\n",
      "accuracy is 0.844783 at times  300\n",
      "accuracy is 0.865967 at times  350\n",
      "accuracy is 0.880816 at times  400\n",
      "accuracy is 0.89309 at times  450\n",
      "accuracy is 0.901208 at times  500\n",
      "accuracy is 0.907741 at times  550\n",
      "accuracy is 0.911503 at times  600\n",
      "accuracy is 0.914274 at times  650\n",
      "accuracy is 0.916452 at times  700\n",
      "accuracy is 0.918234 at times  750\n",
      "accuracy is 0.920214 at times  800\n",
      "accuracy is 0.921996 at times  850\n",
      "accuracy is 0.923777 at times  900\n",
      "accuracy is 0.924569 at times  950\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000): # train 1000 times\n",
    "    sess.run(trainer, feed_dict={x: train_x, y_: train_y})\n",
    "    result = sess.run(merged, feed_dict={x: train_x, y_: train_y})\n",
    "    train_writer.add_summary(result, i)\n",
    "    if i % 50 == 0: # save summary if after train 50 times\n",
    "        result, acc = sess.run([merged, accuracy], feed_dict={x: test_x, y_: test_y})\n",
    "        test_writer.add_summary(result, i)\n",
    "        print \"accuracy is %0.8s at times %4d\" % (acc,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " ..., \n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.]]\n",
      "[[False False  True False False]\n",
      " [False False False  True False]\n",
      " [ True False False False False]\n",
      " ..., \n",
      " [ True False False False False]\n",
      " [False False  True False False]\n",
      " [False False False False  True]]\n"
     ]
    }
   ],
   "source": [
    "print sess.run(y_, feed_dict={x: train_x, y_: train_y})\n",
    "print sess.run(true_index, feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(y_, feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01232991,  0.02073836,  0.87376052,  0.01221038,  0.08096086],\n",
       "       [ 0.00248122,  0.00413203,  0.05257058,  0.89045465,  0.05036161],\n",
       "       [ 0.93920898,  0.02350495,  0.02156768,  0.00410834,  0.01161002],\n",
       "       ..., \n",
       "       [ 0.71395719,  0.09155858,  0.10753477,  0.04913901,  0.03781044],\n",
       "       [ 0.01073636,  0.02185084,  0.93757486,  0.00664217,  0.02319565],\n",
       "       [ 0.01166299,  0.00323938,  0.08034842,  0.04200077,  0.86274838]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(y, feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.87376052,  0.89045465,  0.93920898, ...,  0.71395719,\n",
       "        0.93757486,  0.86274838], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.boolean_mask(y, true_index), feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01232991,  0.02073836,  0.01221038,  0.08096086],\n",
       "       [ 0.00248122,  0.00413203,  0.05257058,  0.05036161],\n",
       "       [ 0.02350495,  0.02156768,  0.00410834,  0.01161002],\n",
       "       ..., \n",
       "       [ 0.09155858,  0.10753477,  0.04913901,  0.03781044],\n",
       "       [ 0.01073636,  0.02185084,  0.00664217,  0.02319565],\n",
       "       [ 0.01166299,  0.00323938,  0.08034842,  0.04200077]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.reshape(tf.boolean_mask(y, ~true_index), [tf.shape(y_)[0], len_numbers-1]), feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08096086,  0.05257058,  0.02350495, ...,  0.10753477,\n",
       "        0.02319565,  0.08034842], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.reduce_max(tf.reshape(tf.boolean_mask(y, ~true_index), [tf.shape(y_)[0], len_numbers-1]), reduction_indices=[1]), \n",
    "             feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79279965,  0.83788407,  0.91570401, ...,  0.60642242,\n",
       "        0.91437924,  0.78239995], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.boolean_mask(y, true_index) - (tf.reduce_max(tf.reshape(tf.boolean_mask(y, ~true_index), [tf.shape(y_)[0], len_numbers-1]), reduction_indices=[1])), \n",
    "             feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.20720035,  0.16211593,  0.08429599, ...,  0.39357758,\n",
       "        0.08562076,  0.21760005], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(1 - (tf.boolean_mask(y, true_index) - (tf.reduce_max(tf.reshape(tf.boolean_mask(y, ~true_index), [tf.shape(y_)[0], len_numbers-1]), reduction_indices=[1]))), \n",
    "             feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_writer.close()\n",
    "test_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shell: \n",
    "```\n",
    "tensorboard --logdir=mnist_logs/\n",
    "```\n",
    "# Browser: http://127.0.0.1:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
