{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mnist_binary(images, labels, binary):\n",
    "#     binary = [binary[0]-1 , binary[1]-1]\n",
    "    select = [i for i,l in enumerate(labels) if sum(l[binary])>=1]\n",
    "    x = images[select]\n",
    "    y = labels[select][:,binary].astype(int)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3, 4, 5]\n",
    "train_x, train_y = mnist_binary(mnist.train.images, mnist.train.labels, numbers)\n",
    "test_x, test_y = mnist_binary(mnist.test.images, mnist.test.labels, numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len_numbers = len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var, name):\n",
    "  \"\"\"Attach a lot of summaries to a Tensor.\"\"\"\n",
    "  with tf.name_scope('summaries'):\n",
    "    mean = tf.reduce_mean(var)\n",
    "    tf.scalar_summary('mean/' + name, mean)\n",
    "    with tf.name_scope('stddev'):\n",
    "      stddev = tf.sqrt(tf.reduce_sum(tf.square(var - mean)))\n",
    "    tf.scalar_summary('sttdev/' + name, stddev)\n",
    "    tf.scalar_summary('max/' + name, tf.reduce_max(var))\n",
    "    tf.scalar_summary('min/' + name, tf.reduce_min(var))\n",
    "    tf.histogram_summary(name, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n",
    "    \"\"\"Reusable code for making a simple neural net layer.\n",
    "    It does a matrix multiply, bias add, and then uses relu to nonlinearize.\n",
    "    It also sets up name scoping so that the resultant graph is easy to read,\n",
    "    and adds a number of summary ops.\n",
    "    \"\"\"\n",
    "    # Adding a name scope ensures logical grouping of the layers in the graph.\n",
    "    with tf.name_scope(layer_name):\n",
    "      # This Variable will hold the state of the weights for the layer\n",
    "      with tf.name_scope('weights'):\n",
    "        weights = weight_variable([input_dim, output_dim])\n",
    "        variable_summaries(weights, layer_name + '/weights')\n",
    "      with tf.name_scope('biases'):\n",
    "        biases = bias_variable([output_dim])\n",
    "        variable_summaries(biases, layer_name + '/biases')\n",
    "      with tf.name_scope('Wx_plus_b'):\n",
    "        preactivate = tf.matmul(input_tensor, weights) + biases\n",
    "        tf.histogram_summary(layer_name + '/pre_activations', preactivate)\n",
    "      activations = act(preactivate, 'activation')\n",
    "      tf.histogram_summary(layer_name + '/activations', activations)\n",
    "      return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set variables\n",
    "with tf.name_scope('input'):\n",
    "  x = tf.placeholder(tf.float32, [None, 784], name='x-input') # 28*28\n",
    "  y_ = tf.placeholder(tf.float32, [None, len_numbers], name='y-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('input_reshape'):\n",
    "  image_shaped_input = tf.reshape(x, [-1, 28, 28, 1])\n",
    "  tf.image_summary('input', image_shaped_input, 10) # 10 sample in IMAGES of tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set graphs and GRAPHS of tensorboard\n",
    "y = nn_layer(x, 784, len_numbers, 'layer1', tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set loss function\n",
    "with tf.name_scope('cross_entropy'):\n",
    "  diff = y_ * tf.log(y + 1e-10)\n",
    "  with tf.name_scope('total'):\n",
    "    cross_entropy = -tf.reduce_mean(diff)\n",
    "  tf.scalar_summary('cross entropy', cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Set hinge loss function for binary class\n",
    "# with tf.name_scope('cross_entropy'):\n",
    "#   with tf.name_scope('total'):\n",
    "#     hinge_loss = tf.reduce_mean(tf.maximum(0., 1. - (y_[:,1] - y_[:,0])*y[:,1]))\n",
    "#   tf.scalar_summary('hinge_loss', hinge_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set hinge loss function for multiclass\n",
    "with tf.name_scope('cross_entropy'):\n",
    "  true_index = tf.cast(y_, dtype = bool)\n",
    "  margin = tf.boolean_mask(y, true_index)\n",
    "  false_prediction = tf.reshape(tf.boolean_mask(y, ~true_index), [tf.shape(y_)[0], len_numbers-1])\n",
    "  false_prediction_max = tf.reduce_max(false_prediction, reduction_indices=[1])\n",
    "  loss = 1 - (margin - false_prediction_max)\n",
    "  loss = tf.maximum(loss, tf.zeros_like(loss))\n",
    "  with tf.name_scope('total'):\n",
    "    hinge_loss = tf.reduce_mean(loss)\n",
    "  tf.scalar_summary('hinge_loss', hinge_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsuehhungcheng/.pyenv/versions/anaconda-4.0.0/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py:90: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "# Set optimizer method\n",
    "with tf.variable_scope(\"trainer\") as scope:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "#     trainer = optimizer.minimize(cross_entropy)\n",
    "    trainer = optimizer.minimize(hinge_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('accuracy'):\n",
    "  with tf.name_scope('correct_prediction'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "  with tf.name_scope('accuracy'):\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "  tf.scalar_summary('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = tf.merge_all_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_writer = tf.train.SummaryWriter('mnist_logs' + '/train', sess.graph)\n",
    "test_writer = tf.train.SummaryWriter('mnist_logs' + '/test', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.064739 at times    0\n",
      "accuracy is 0.195803 at times   50\n",
      "accuracy is 0.324292 at times  100\n",
      "accuracy is 0.46565 at times  150\n",
      "accuracy is 0.599089 at times  200\n",
      "accuracy is 0.679073 at times  250\n",
      "accuracy is 0.721639 at times  300\n",
      "accuracy is 0.752524 at times  350\n",
      "accuracy is 0.775094 at times  400\n",
      "accuracy is 0.799644 at times  450\n",
      "accuracy is 0.823401 at times  500\n",
      "accuracy is 0.843199 at times  550\n",
      "accuracy is 0.859434 at times  600\n",
      "accuracy is 0.868937 at times  650\n",
      "accuracy is 0.875272 at times  700\n",
      "accuracy is 0.883191 at times  750\n",
      "accuracy is 0.889527 at times  800\n",
      "accuracy is 0.893288 at times  850\n",
      "accuracy is 0.895268 at times  900\n",
      "accuracy is 0.897446 at times  950\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000): # train 1000 times\n",
    "    sess.run(trainer, feed_dict={x: train_x, y_: train_y})\n",
    "    result = sess.run(merged, feed_dict={x: train_x, y_: train_y})\n",
    "    train_writer.add_summary(result, i)\n",
    "    if i % 50 == 0: # save summary if after train 50 times\n",
    "        result, acc = sess.run([merged, accuracy], feed_dict={x: test_x, y_: test_y})\n",
    "        test_writer.add_summary(result, i)\n",
    "        print \"accuracy is %0.8s at times %4d\" % (acc,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " ..., \n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.]]\n",
      "[[False False  True False False]\n",
      " [False False False  True False]\n",
      " [ True False False False False]\n",
      " ..., \n",
      " [ True False False False False]\n",
      " [False False  True False False]\n",
      " [False False False False  True]]\n"
     ]
    }
   ],
   "source": [
    "print sess.run(y_, feed_dict={x: train_x, y_: train_y})\n",
    "print sess.run(true_index, feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(y_, feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01380698,  0.01795236,  0.88862532,  0.00985783,  0.06975739],\n",
       "       [ 0.0019449 ,  0.00906196,  0.0793579 ,  0.83552766,  0.07410766],\n",
       "       [ 0.97283369,  0.00863509,  0.01037223,  0.00349912,  0.00465986],\n",
       "       ..., \n",
       "       [ 0.76397556,  0.09182667,  0.07625485,  0.02989758,  0.03804537],\n",
       "       [ 0.00455048,  0.02500125,  0.91919816,  0.00381381,  0.04743636],\n",
       "       [ 0.02219394,  0.00259264,  0.05593104,  0.03593724,  0.88334519]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(y, feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.88862532,  0.83552766,  0.97283369, ...,  0.76397556,\n",
       "        0.91919816,  0.88334519], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.boolean_mask(y, true_index), feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01380698,  0.01795236,  0.00985783,  0.06975739],\n",
       "       [ 0.0019449 ,  0.00906196,  0.0793579 ,  0.07410766],\n",
       "       [ 0.00863509,  0.01037223,  0.00349912,  0.00465986],\n",
       "       ..., \n",
       "       [ 0.09182667,  0.07625485,  0.02989758,  0.03804537],\n",
       "       [ 0.00455048,  0.02500125,  0.00381381,  0.04743636],\n",
       "       [ 0.02219394,  0.00259264,  0.05593104,  0.03593724]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.reshape(tf.boolean_mask(y, ~true_index), [tf.shape(y_)[0], len_numbers-1]), feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06975739,  0.0793579 ,  0.01037223, ...,  0.09182667,\n",
       "        0.04743636,  0.05593104], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.reduce_max(tf.reshape(tf.boolean_mask(y, ~true_index), [tf.shape(y_)[0], len_numbers-1]), reduction_indices=[1]), \n",
    "             feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.81886792,  0.75616974,  0.96246147, ...,  0.67214888,\n",
       "        0.8717618 ,  0.82741416], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.boolean_mask(y, true_index) - (tf.reduce_max(tf.reshape(tf.boolean_mask(y, ~true_index), [tf.shape(y_)[0], len_numbers-1]), reduction_indices=[1])), \n",
    "             feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.18113208,  0.24383026,  0.03753853, ...,  0.32785112,\n",
       "        0.1282382 ,  0.17258584], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(1 - (tf.boolean_mask(y, true_index) - (tf.reduce_max(tf.reshape(tf.boolean_mask(y, ~true_index), [tf.shape(y_)[0], len_numbers-1]), reduction_indices=[1]))), \n",
    "             feed_dict={x: train_x, y_: train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_writer.close()\n",
    "test_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shell: \n",
    "```\n",
    "tensorboard --logdir=mnist_logs/\n",
    "```\n",
    "# Browser: http://127.0.0.1:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
